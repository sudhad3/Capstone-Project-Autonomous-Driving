{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Semantic Segmentation V4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxXF5QkFKyoL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "7c1381ae-362e-444a-9046-fe4b446ff3a8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chgjkCWIK8T5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a389cd36-adf9-4f71-b19e-1432f7819f3c"
      },
      "source": [
        "cd 'drive/My Drive/'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y35bfbH2NvzV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f597b573-5f21-41fa-c9ec-c6825540d02d"
      },
      "source": [
        "ls 'Selected'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mtrain_color\u001b[0m/  \u001b[01;34mtrain_label\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CcpoxYtrOaHP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "outputId": "4e1b04d1-804d-42f2-97dd-ef47cc840d6f"
      },
      "source": [
        "!pip install segmentation_models"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: segmentation_models in /usr/local/lib/python3.6/dist-packages (1.0.0)\n",
            "Requirement already satisfied: image-classifiers==1.0.0 in /usr/local/lib/python3.6/dist-packages (from segmentation_models) (1.0.0)\n",
            "Requirement already satisfied: keras-applications<=1.0.8,>=1.0.7 in /usr/local/lib/python3.6/dist-packages (from segmentation_models) (1.0.8)\n",
            "Requirement already satisfied: efficientnet==1.0.0 in /usr/local/lib/python3.6/dist-packages (from segmentation_models) (1.0.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation_models) (2.8.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation_models) (1.17.4)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (from efficientnet==1.0.0->segmentation_models) (0.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->segmentation_models) (1.12.0)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (1.1.1)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (4.3.0)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (3.1.2)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (1.3.3)\n",
            "Requirement already satisfied: imageio>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2.4.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2.4)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.3.0->scikit-image->efficientnet==1.0.0->segmentation_models) (0.46)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (2.6.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (1.1.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (2.4.5)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image->efficientnet==1.0.0->segmentation_models) (4.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (42.0.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JePc5aHOROy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        },
        "outputId": "f3251cb6-4056-4a85-e311-0f118fa9bd25"
      },
      "source": [
        "#Importing necessary libraries\n",
        "import os\n",
        "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"  #- Uncomment this to run tensorflow on CPU\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use(\"ggplot\")\n",
        "%matplotlib inline\n",
        "from glob import glob\n",
        "\n",
        "from tqdm import tqdm_notebook, tnrange\n",
        "from itertools import chain\n",
        "from skimage.io import imread, imshow, concatenate_images\n",
        "from skimage.transform import resize\n",
        "from skimage.morphology import label\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input, BatchNormalization, Activation, Dense, Dropout\n",
        "from keras.layers.core import Lambda, RepeatVector, Reshape\n",
        "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
        "from keras.layers.pooling import MaxPooling2D, GlobalMaxPool2D\n",
        "from keras.layers.merge import concatenate, add\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "\n",
        "import segmentation_models as sm"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Segmentation Models: using `keras` framework.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_cYcBoEOjaF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "09658118-0c1c-4aa7-9626-a1a2820cb7fa"
      },
      "source": [
        "IMG_HEIGHT = 256\n",
        "IMG_WIDTH = 256\n",
        "\n",
        "IMG_DIR  = os.path.join('.', 'Selected', 'train_color')\n",
        "MASK_DIR = os.path.join('.', 'Selected', 'train_label')\n",
        "\n",
        "BACKBONE = 'seresnet34'\n",
        "preprocess_input = sm.get_preprocessing(BACKBONE)\n",
        "\n",
        "INPUT_SIZE = (IMG_HEIGHT, IMG_WIDTH, 3)\n",
        "INPUT_MASK_SIZE = (IMG_HEIGHT, IMG_WIDTH, 1)\n",
        "\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "IMG_DIR, MASK_DIR"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./Selected/train_color', './Selected/train_label')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlA5LN6lPa0m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "1c6ea796-0d19-410f-cdd7-547afa3dc2c6"
      },
      "source": [
        "img_paths  = pd.DataFrame(dict(path = glob(os.path.join(MASK_DIR, '*.*p*g'))))\n",
        "mask_paths = pd.DataFrame(dict(path = glob(os.path.join(IMG_DIR, '*.*j*g'))))\n",
        "\n",
        "all_paths = img_paths.append(mask_paths)\n",
        "all_paths['group'] = all_paths['path'].map(lambda x: x.split(f'{os.sep}')[-2].split('_')[-1])\n",
        "all_paths['id'] = all_paths['path'].map(lambda x: '_'.join(os.path.splitext(os.path.basename(x))[0].split('_')[0:4]))\n",
        "all_paths.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>group</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>./Selected/train_label/170908_061534099_Camera...</td>\n",
              "      <td>label</td>\n",
              "      <td>170908_061534099_Camera_6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>./Selected/train_label/170908_061534516_Camera...</td>\n",
              "      <td>label</td>\n",
              "      <td>170908_061534516_Camera_5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>./Selected/train_label/170908_061534655_Camera...</td>\n",
              "      <td>label</td>\n",
              "      <td>170908_061534655_Camera_5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>./Selected/train_label/170908_061535350_Camera...</td>\n",
              "      <td>label</td>\n",
              "      <td>170908_061535350_Camera_5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>./Selected/train_label/170908_061534655_Camera...</td>\n",
              "      <td>label</td>\n",
              "      <td>170908_061534655_Camera_6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                path  ...                         id\n",
              "0  ./Selected/train_label/170908_061534099_Camera...  ...  170908_061534099_Camera_6\n",
              "1  ./Selected/train_label/170908_061534516_Camera...  ...  170908_061534516_Camera_5\n",
              "2  ./Selected/train_label/170908_061534655_Camera...  ...  170908_061534655_Camera_5\n",
              "3  ./Selected/train_label/170908_061535350_Camera...  ...  170908_061535350_Camera_5\n",
              "4  ./Selected/train_label/170908_061534655_Camera...  ...  170908_061534655_Camera_6\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yhAFf_1PbTr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "9b22654b-406f-4dd8-c0a6-73ddcc89a803"
      },
      "source": [
        "group_df = all_paths.pivot_table(values = 'path', columns = 'group', aggfunc = 'first', index = ['id']).reset_index()\n",
        "group_df.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>group</th>\n",
              "      <th>id</th>\n",
              "      <th>color</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>170908_061502408_Camera_5</td>\n",
              "      <td>./Selected/train_color/170908_061502408_Camera...</td>\n",
              "      <td>./Selected/train_label/170908_061502408_Camera...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>170908_061502408_Camera_6</td>\n",
              "      <td>./Selected/train_color/170908_061502408_Camera...</td>\n",
              "      <td>./Selected/train_label/170908_061502408_Camera...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>170908_061502547_Camera_5</td>\n",
              "      <td>./Selected/train_color/170908_061502547_Camera...</td>\n",
              "      <td>./Selected/train_label/170908_061502547_Camera...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>170908_061502547_Camera_6</td>\n",
              "      <td>./Selected/train_color/170908_061502547_Camera...</td>\n",
              "      <td>./Selected/train_label/170908_061502547_Camera...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>170908_061502686_Camera_5</td>\n",
              "      <td>./Selected/train_color/170908_061502686_Camera...</td>\n",
              "      <td>./Selected/train_label/170908_061502686_Camera...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "group                         id  ...                                              label\n",
              "0      170908_061502408_Camera_5  ...  ./Selected/train_label/170908_061502408_Camera...\n",
              "1      170908_061502408_Camera_6  ...  ./Selected/train_label/170908_061502408_Camera...\n",
              "2      170908_061502547_Camera_5  ...  ./Selected/train_label/170908_061502547_Camera...\n",
              "3      170908_061502547_Camera_6  ...  ./Selected/train_label/170908_061502547_Camera...\n",
              "4      170908_061502686_Camera_5  ...  ./Selected/train_label/170908_061502686_Camera...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68iNOEViPbZY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_split_df, valid_split_df = train_test_split(group_df, random_state = 2018, test_size = 0.25)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okyNLTdKQIcQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "\n",
        "def data_gen(df, size=16, normalize=True):\n",
        "    if size > df.shape[0]:\n",
        "        print('Size is bigger than available number of images. Please specify a smaller size than ', df.shape[0])\n",
        "        return\n",
        "    elif size < 0:\n",
        "        print('Size should be greater than zero ', df.shape[0])\n",
        "\n",
        "    ids = df['id'].tolist()\n",
        "    random.shuffle(ids)\n",
        "  \n",
        "    for i in range(size):\n",
        "        img = np.zeros((size, IMG_HEIGHT, IMG_WIDTH, 3)).astype('float')\n",
        "        mask = np.zeros((size, IMG_HEIGHT, IMG_WIDTH, 1)).astype('float')\n",
        "\n",
        "        img_path  = df.loc[df['id'] == ids[i]]['color'].values[0]\n",
        "        mask_path = df.loc[df['id'] == ids[i]]['label'].values[0]\n",
        "        #print(\"Pair:\")\n",
        "        #print(\"\\t\", img_path)\n",
        "        #print(\"\\t\", mask_path)\n",
        "\n",
        "        train_img = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)\n",
        "        if normalize:\n",
        "            train_img = train_img/255.\n",
        "        train_img =  cv2.resize(train_img, (IMG_WIDTH, IMG_HEIGHT))# Read an image from folder and resize\n",
        "\n",
        "        img[i] = train_img #add to array - img[0], img[1], and so on.\n",
        "\n",
        "\n",
        "        train_mask = cv2.imread(mask_path, cv2.IMREAD_UNCHANGED)\n",
        "        t_mask = np.where(train_mask<33000, 0, train_mask)\n",
        "        #train_mask = (t_mask//1000) + ((t_mask%1000)/100)            \n",
        "        train_mask = (t_mask//1000)\n",
        "\n",
        "        train_mask = cv2.resize(train_mask, (IMG_WIDTH, IMG_HEIGHT), interpolation = cv2.INTER_NEAREST)\n",
        "        train_mask = train_mask.reshape(IMG_HEIGHT, IMG_WIDTH, 1) # Add extra dimension for parity with train_img size [384 * 384 * 3]\n",
        "\n",
        "        mask[i] = train_mask\n",
        "\n",
        "        \n",
        "        if((i+1)%500 == 0):\n",
        "            random.shuffle(ids)\n",
        "            print('randomizing again')\n",
        "        \n",
        "    return img, mask"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDpARjKeQIgE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, y_train = data_gen(train_split_df, size=384, normalize=True)\n",
        "X_valid, y_valid = data_gen(valid_split_df, size=32, normalize=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4-Gtm1dQIju",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f7bbe3cf-f79b-460d-e915-7afea30e313c"
      },
      "source": [
        "X_train.shape, y_train.shape, X_valid.shape, y_valid.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((384, 256, 256, 3), (384, 256, 256, 1), (32, 256, 256, 3), (32, 256, 256, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mt-nTAj_U0eA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dice_coefficient(y_true, y_pred):\n",
        "    numerator = 2 * tf.reduce_sum(y_true * y_pred)\n",
        "    denominator = tf.reduce_sum(y_true + y_pred)\n",
        "\n",
        "    return numerator / (denominator + tf.keras.backend.epsilon())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkuWMmGaU0hT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.losses import binary_crossentropy\n",
        "def loss(y_true, y_pred):\n",
        "    return binary_crossentropy(y_true, y_pred) - tf.math.log(dice_coefficient(y_true, y_pred) + tf.keras.backend.epsilon())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-EdZMIaU0kQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9c5f2070-0f26-4b70-e8ce-1b69558a28d2"
      },
      "source": [
        "#x_train = preprocess_input(X_train)\n",
        "#x_valid = preprocess_input(X_valid)\n",
        "x_train = X_train\n",
        "x_valid = X_valid\n",
        "\n",
        "model = sm.Unet(backbone_name=BACKBONE, encoder_weights='imagenet', input_shape=(None, None, 3), encoder_freeze=True)\n",
        "model.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2239: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
            "\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "data (InputLayer)               (None, None, None, 3 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bn_data (BatchNormalization)    (None, None, None, 3 9           data[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_1 (ZeroPadding2D (None, None, None, 3 0           bn_data[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv0 (Conv2D)                  (None, None, None, 6 9408        zero_padding2d_1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "bn0 (BatchNormalization)        (None, None, None, 6 256         conv0[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "relu0 (Activation)              (None, None, None, 6 0           bn0[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_2 (ZeroPadding2D (None, None, None, 6 0           relu0[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "pooling0 (MaxPooling2D)         (None, None, None, 6 0           zero_padding2d_2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit1_bn1 (BatchNormaliz (None, None, None, 6 256         pooling0[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit1_relu1 (Activation) (None, None, None, 6 0           stage1_unit1_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_3 (ZeroPadding2D (None, None, None, 6 0           stage1_unit1_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit1_conv1 (Conv2D)     (None, None, None, 6 36864       zero_padding2d_3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit1_bn2 (BatchNormaliz (None, None, None, 6 256         stage1_unit1_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit1_relu2 (Activation) (None, None, None, 6 0           stage1_unit1_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_4 (ZeroPadding2D (None, None, None, 6 0           stage1_unit1_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit1_conv2 (Conv2D)     (None, None, None, 6 36864       zero_padding2d_4[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_1 (Glo (None, 64)           0           stage1_unit1_conv2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 1, 1, 64)     0           global_average_pooling2d_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 1, 1, 4)      260         lambda_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 1, 1, 4)      0           conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 1, 1, 64)     320         activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 1, 1, 64)     0           conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "multiply_1 (Multiply)           (None, None, None, 6 0           stage1_unit1_conv2[0][0]         \n",
            "                                                                 activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit1_sc (Conv2D)        (None, None, None, 6 4096        stage1_unit1_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, None, None, 6 0           multiply_1[0][0]                 \n",
            "                                                                 stage1_unit1_sc[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit2_bn1 (BatchNormaliz (None, None, None, 6 256         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit2_relu1 (Activation) (None, None, None, 6 0           stage1_unit2_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_5 (ZeroPadding2D (None, None, None, 6 0           stage1_unit2_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit2_conv1 (Conv2D)     (None, None, None, 6 36864       zero_padding2d_5[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit2_bn2 (BatchNormaliz (None, None, None, 6 256         stage1_unit2_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit2_relu2 (Activation) (None, None, None, 6 0           stage1_unit2_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_6 (ZeroPadding2D (None, None, None, 6 0           stage1_unit2_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit2_conv2 (Conv2D)     (None, None, None, 6 36864       zero_padding2d_6[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_2 (Glo (None, 64)           0           stage1_unit2_conv2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2 (Lambda)               (None, 1, 1, 64)     0           global_average_pooling2d_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 1, 1, 4)      260         lambda_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 1, 1, 4)      0           conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 1, 1, 64)     320         activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 1, 1, 64)     0           conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "multiply_2 (Multiply)           (None, None, None, 6 0           stage1_unit2_conv2[0][0]         \n",
            "                                                                 activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, None, None, 6 0           multiply_2[0][0]                 \n",
            "                                                                 add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit3_bn1 (BatchNormaliz (None, None, None, 6 256         add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit3_relu1 (Activation) (None, None, None, 6 0           stage1_unit3_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_7 (ZeroPadding2D (None, None, None, 6 0           stage1_unit3_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit3_conv1 (Conv2D)     (None, None, None, 6 36864       zero_padding2d_7[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit3_bn2 (BatchNormaliz (None, None, None, 6 256         stage1_unit3_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit3_relu2 (Activation) (None, None, None, 6 0           stage1_unit3_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_8 (ZeroPadding2D (None, None, None, 6 0           stage1_unit3_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit3_conv2 (Conv2D)     (None, None, None, 6 36864       zero_padding2d_8[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_3 (Glo (None, 64)           0           stage1_unit3_conv2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3 (Lambda)               (None, 1, 1, 64)     0           global_average_pooling2d_3[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 1, 1, 4)      260         lambda_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 1, 1, 4)      0           conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 1, 1, 64)     320         activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 1, 1, 64)     0           conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "multiply_3 (Multiply)           (None, None, None, 6 0           stage1_unit3_conv2[0][0]         \n",
            "                                                                 activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, None, None, 6 0           multiply_3[0][0]                 \n",
            "                                                                 add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit1_bn1 (BatchNormaliz (None, None, None, 6 256         add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit1_relu1 (Activation) (None, None, None, 6 0           stage2_unit1_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_9 (ZeroPadding2D (None, None, None, 6 0           stage2_unit1_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit1_conv1 (Conv2D)     (None, None, None, 1 73728       zero_padding2d_9[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit1_bn2 (BatchNormaliz (None, None, None, 1 512         stage2_unit1_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit1_relu2 (Activation) (None, None, None, 1 0           stage2_unit1_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_10 (ZeroPadding2 (None, None, None, 1 0           stage2_unit1_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit1_conv2 (Conv2D)     (None, None, None, 1 147456      zero_padding2d_10[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_4 (Glo (None, 128)          0           stage2_unit1_conv2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4 (Lambda)               (None, 1, 1, 128)    0           global_average_pooling2d_4[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 1, 1, 8)      1032        lambda_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 1, 1, 8)      0           conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 1, 1, 128)    1152        activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 1, 1, 128)    0           conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "multiply_4 (Multiply)           (None, None, None, 1 0           stage2_unit1_conv2[0][0]         \n",
            "                                                                 activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit1_sc (Conv2D)        (None, None, None, 1 8192        stage2_unit1_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, None, None, 1 0           multiply_4[0][0]                 \n",
            "                                                                 stage2_unit1_sc[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit2_bn1 (BatchNormaliz (None, None, None, 1 512         add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit2_relu1 (Activation) (None, None, None, 1 0           stage2_unit2_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_11 (ZeroPadding2 (None, None, None, 1 0           stage2_unit2_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit2_conv1 (Conv2D)     (None, None, None, 1 147456      zero_padding2d_11[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit2_bn2 (BatchNormaliz (None, None, None, 1 512         stage2_unit2_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit2_relu2 (Activation) (None, None, None, 1 0           stage2_unit2_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_12 (ZeroPadding2 (None, None, None, 1 0           stage2_unit2_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit2_conv2 (Conv2D)     (None, None, None, 1 147456      zero_padding2d_12[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_5 (Glo (None, 128)          0           stage2_unit2_conv2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "lambda_5 (Lambda)               (None, 1, 1, 128)    0           global_average_pooling2d_5[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 1, 1, 8)      1032        lambda_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 1, 1, 8)      0           conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 1, 1, 128)    1152        activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 1, 1, 128)    0           conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply_5 (Multiply)           (None, None, None, 1 0           stage2_unit2_conv2[0][0]         \n",
            "                                                                 activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, None, None, 1 0           multiply_5[0][0]                 \n",
            "                                                                 add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit3_bn1 (BatchNormaliz (None, None, None, 1 512         add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit3_relu1 (Activation) (None, None, None, 1 0           stage2_unit3_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_13 (ZeroPadding2 (None, None, None, 1 0           stage2_unit3_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit3_conv1 (Conv2D)     (None, None, None, 1 147456      zero_padding2d_13[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit3_bn2 (BatchNormaliz (None, None, None, 1 512         stage2_unit3_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit3_relu2 (Activation) (None, None, None, 1 0           stage2_unit3_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_14 (ZeroPadding2 (None, None, None, 1 0           stage2_unit3_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit3_conv2 (Conv2D)     (None, None, None, 1 147456      zero_padding2d_14[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_6 (Glo (None, 128)          0           stage2_unit3_conv2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "lambda_6 (Lambda)               (None, 1, 1, 128)    0           global_average_pooling2d_6[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 1, 1, 8)      1032        lambda_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 1, 1, 8)      0           conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 1, 1, 128)    1152        activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 1, 1, 128)    0           conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply_6 (Multiply)           (None, None, None, 1 0           stage2_unit3_conv2[0][0]         \n",
            "                                                                 activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, None, None, 1 0           multiply_6[0][0]                 \n",
            "                                                                 add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit4_bn1 (BatchNormaliz (None, None, None, 1 512         add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit4_relu1 (Activation) (None, None, None, 1 0           stage2_unit4_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_15 (ZeroPadding2 (None, None, None, 1 0           stage2_unit4_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit4_conv1 (Conv2D)     (None, None, None, 1 147456      zero_padding2d_15[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit4_bn2 (BatchNormaliz (None, None, None, 1 512         stage2_unit4_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit4_relu2 (Activation) (None, None, None, 1 0           stage2_unit4_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_16 (ZeroPadding2 (None, None, None, 1 0           stage2_unit4_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit4_conv2 (Conv2D)     (None, None, None, 1 147456      zero_padding2d_16[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_7 (Glo (None, 128)          0           stage2_unit4_conv2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "lambda_7 (Lambda)               (None, 1, 1, 128)    0           global_average_pooling2d_7[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 1, 1, 8)      1032        lambda_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 1, 1, 8)      0           conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 1, 1, 128)    1152        activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 1, 1, 128)    0           conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply_7 (Multiply)           (None, None, None, 1 0           stage2_unit4_conv2[0][0]         \n",
            "                                                                 activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, None, None, 1 0           multiply_7[0][0]                 \n",
            "                                                                 add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit1_bn1 (BatchNormaliz (None, None, None, 1 512         add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit1_relu1 (Activation) (None, None, None, 1 0           stage3_unit1_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_17 (ZeroPadding2 (None, None, None, 1 0           stage3_unit1_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit1_conv1 (Conv2D)     (None, None, None, 2 294912      zero_padding2d_17[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit1_bn2 (BatchNormaliz (None, None, None, 2 1024        stage3_unit1_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit1_relu2 (Activation) (None, None, None, 2 0           stage3_unit1_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_18 (ZeroPadding2 (None, None, None, 2 0           stage3_unit1_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit1_conv2 (Conv2D)     (None, None, None, 2 589824      zero_padding2d_18[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_8 (Glo (None, 256)          0           stage3_unit1_conv2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "lambda_8 (Lambda)               (None, 1, 1, 256)    0           global_average_pooling2d_8[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 1, 1, 16)     4112        lambda_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 1, 1, 16)     0           conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 1, 1, 256)    4352        activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 1, 1, 256)    0           conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply_8 (Multiply)           (None, None, None, 2 0           stage3_unit1_conv2[0][0]         \n",
            "                                                                 activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit1_sc (Conv2D)        (None, None, None, 2 32768       stage3_unit1_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, None, None, 2 0           multiply_8[0][0]                 \n",
            "                                                                 stage3_unit1_sc[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit2_bn1 (BatchNormaliz (None, None, None, 2 1024        add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit2_relu1 (Activation) (None, None, None, 2 0           stage3_unit2_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_19 (ZeroPadding2 (None, None, None, 2 0           stage3_unit2_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit2_conv1 (Conv2D)     (None, None, None, 2 589824      zero_padding2d_19[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit2_bn2 (BatchNormaliz (None, None, None, 2 1024        stage3_unit2_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit2_relu2 (Activation) (None, None, None, 2 0           stage3_unit2_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_20 (ZeroPadding2 (None, None, None, 2 0           stage3_unit2_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit2_conv2 (Conv2D)     (None, None, None, 2 589824      zero_padding2d_20[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_9 (Glo (None, 256)          0           stage3_unit2_conv2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "lambda_9 (Lambda)               (None, 1, 1, 256)    0           global_average_pooling2d_9[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 1, 1, 16)     4112        lambda_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 1, 1, 16)     0           conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 1, 1, 256)    4352        activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 1, 1, 256)    0           conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply_9 (Multiply)           (None, None, None, 2 0           stage3_unit2_conv2[0][0]         \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, None, None, 2 0           multiply_9[0][0]                 \n",
            "                                                                 add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit3_bn1 (BatchNormaliz (None, None, None, 2 1024        add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit3_relu1 (Activation) (None, None, None, 2 0           stage3_unit3_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_21 (ZeroPadding2 (None, None, None, 2 0           stage3_unit3_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit3_conv1 (Conv2D)     (None, None, None, 2 589824      zero_padding2d_21[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit3_bn2 (BatchNormaliz (None, None, None, 2 1024        stage3_unit3_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit3_relu2 (Activation) (None, None, None, 2 0           stage3_unit3_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_22 (ZeroPadding2 (None, None, None, 2 0           stage3_unit3_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit3_conv2 (Conv2D)     (None, None, None, 2 589824      zero_padding2d_22[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_10 (Gl (None, 256)          0           stage3_unit3_conv2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "lambda_10 (Lambda)              (None, 1, 1, 256)    0           global_average_pooling2d_10[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 1, 1, 16)     4112        lambda_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 1, 1, 16)     0           conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 1, 1, 256)    4352        activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 1, 1, 256)    0           conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply_10 (Multiply)          (None, None, None, 2 0           stage3_unit3_conv2[0][0]         \n",
            "                                                                 activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, None, None, 2 0           multiply_10[0][0]                \n",
            "                                                                 add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit4_bn1 (BatchNormaliz (None, None, None, 2 1024        add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit4_relu1 (Activation) (None, None, None, 2 0           stage3_unit4_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_23 (ZeroPadding2 (None, None, None, 2 0           stage3_unit4_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit4_conv1 (Conv2D)     (None, None, None, 2 589824      zero_padding2d_23[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit4_bn2 (BatchNormaliz (None, None, None, 2 1024        stage3_unit4_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit4_relu2 (Activation) (None, None, None, 2 0           stage3_unit4_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_24 (ZeroPadding2 (None, None, None, 2 0           stage3_unit4_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit4_conv2 (Conv2D)     (None, None, None, 2 589824      zero_padding2d_24[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_11 (Gl (None, 256)          0           stage3_unit4_conv2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "lambda_11 (Lambda)              (None, 1, 1, 256)    0           global_average_pooling2d_11[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 1, 1, 16)     4112        lambda_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 1, 1, 16)     0           conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 1, 1, 256)    4352        activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 1, 1, 256)    0           conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply_11 (Multiply)          (None, None, None, 2 0           stage3_unit4_conv2[0][0]         \n",
            "                                                                 activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, None, None, 2 0           multiply_11[0][0]                \n",
            "                                                                 add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit5_bn1 (BatchNormaliz (None, None, None, 2 1024        add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit5_relu1 (Activation) (None, None, None, 2 0           stage3_unit5_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_25 (ZeroPadding2 (None, None, None, 2 0           stage3_unit5_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit5_conv1 (Conv2D)     (None, None, None, 2 589824      zero_padding2d_25[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit5_bn2 (BatchNormaliz (None, None, None, 2 1024        stage3_unit5_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit5_relu2 (Activation) (None, None, None, 2 0           stage3_unit5_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_26 (ZeroPadding2 (None, None, None, 2 0           stage3_unit5_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit5_conv2 (Conv2D)     (None, None, None, 2 589824      zero_padding2d_26[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_12 (Gl (None, 256)          0           stage3_unit5_conv2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "lambda_12 (Lambda)              (None, 1, 1, 256)    0           global_average_pooling2d_12[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 1, 1, 16)     4112        lambda_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 1, 1, 16)     0           conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 1, 1, 256)    4352        activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 1, 1, 256)    0           conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply_12 (Multiply)          (None, None, None, 2 0           stage3_unit5_conv2[0][0]         \n",
            "                                                                 activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, None, None, 2 0           multiply_12[0][0]                \n",
            "                                                                 add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit6_bn1 (BatchNormaliz (None, None, None, 2 1024        add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit6_relu1 (Activation) (None, None, None, 2 0           stage3_unit6_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_27 (ZeroPadding2 (None, None, None, 2 0           stage3_unit6_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit6_conv1 (Conv2D)     (None, None, None, 2 589824      zero_padding2d_27[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit6_bn2 (BatchNormaliz (None, None, None, 2 1024        stage3_unit6_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit6_relu2 (Activation) (None, None, None, 2 0           stage3_unit6_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_28 (ZeroPadding2 (None, None, None, 2 0           stage3_unit6_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit6_conv2 (Conv2D)     (None, None, None, 2 589824      zero_padding2d_28[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_13 (Gl (None, 256)          0           stage3_unit6_conv2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "lambda_13 (Lambda)              (None, 1, 1, 256)    0           global_average_pooling2d_13[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 1, 1, 16)     4112        lambda_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 1, 1, 16)     0           conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 1, 1, 256)    4352        activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 1, 1, 256)    0           conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply_13 (Multiply)          (None, None, None, 2 0           stage3_unit6_conv2[0][0]         \n",
            "                                                                 activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, None, None, 2 0           multiply_13[0][0]                \n",
            "                                                                 add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit1_bn1 (BatchNormaliz (None, None, None, 2 1024        add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit1_relu1 (Activation) (None, None, None, 2 0           stage4_unit1_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_29 (ZeroPadding2 (None, None, None, 2 0           stage4_unit1_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit1_conv1 (Conv2D)     (None, None, None, 5 1179648     zero_padding2d_29[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit1_bn2 (BatchNormaliz (None, None, None, 5 2048        stage4_unit1_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit1_relu2 (Activation) (None, None, None, 5 0           stage4_unit1_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_30 (ZeroPadding2 (None, None, None, 5 0           stage4_unit1_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit1_conv2 (Conv2D)     (None, None, None, 5 2359296     zero_padding2d_30[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_14 (Gl (None, 512)          0           stage4_unit1_conv2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "lambda_14 (Lambda)              (None, 1, 1, 512)    0           global_average_pooling2d_14[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 1, 1, 32)     16416       lambda_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 1, 1, 32)     0           conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 1, 1, 512)    16896       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 1, 1, 512)    0           conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply_14 (Multiply)          (None, None, None, 5 0           stage4_unit1_conv2[0][0]         \n",
            "                                                                 activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit1_sc (Conv2D)        (None, None, None, 5 131072      stage4_unit1_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, None, None, 5 0           multiply_14[0][0]                \n",
            "                                                                 stage4_unit1_sc[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit2_bn1 (BatchNormaliz (None, None, None, 5 2048        add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit2_relu1 (Activation) (None, None, None, 5 0           stage4_unit2_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_31 (ZeroPadding2 (None, None, None, 5 0           stage4_unit2_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit2_conv1 (Conv2D)     (None, None, None, 5 2359296     zero_padding2d_31[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit2_bn2 (BatchNormaliz (None, None, None, 5 2048        stage4_unit2_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit2_relu2 (Activation) (None, None, None, 5 0           stage4_unit2_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_32 (ZeroPadding2 (None, None, None, 5 0           stage4_unit2_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit2_conv2 (Conv2D)     (None, None, None, 5 2359296     zero_padding2d_32[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_15 (Gl (None, 512)          0           stage4_unit2_conv2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "lambda_15 (Lambda)              (None, 1, 1, 512)    0           global_average_pooling2d_15[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 1, 1, 32)     16416       lambda_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 1, 1, 32)     0           conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 1, 1, 512)    16896       activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 1, 1, 512)    0           conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply_15 (Multiply)          (None, None, None, 5 0           stage4_unit2_conv2[0][0]         \n",
            "                                                                 activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, None, None, 5 0           multiply_15[0][0]                \n",
            "                                                                 add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit3_bn1 (BatchNormaliz (None, None, None, 5 2048        add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit3_relu1 (Activation) (None, None, None, 5 0           stage4_unit3_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_33 (ZeroPadding2 (None, None, None, 5 0           stage4_unit3_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit3_conv1 (Conv2D)     (None, None, None, 5 2359296     zero_padding2d_33[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit3_bn2 (BatchNormaliz (None, None, None, 5 2048        stage4_unit3_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit3_relu2 (Activation) (None, None, None, 5 0           stage4_unit3_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_34 (ZeroPadding2 (None, None, None, 5 0           stage4_unit3_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit3_conv2 (Conv2D)     (None, None, None, 5 2359296     zero_padding2d_34[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_16 (Gl (None, 512)          0           stage4_unit3_conv2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "lambda_16 (Lambda)              (None, 1, 1, 512)    0           global_average_pooling2d_16[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 1, 1, 32)     16416       lambda_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 1, 1, 32)     0           conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 1, 1, 512)    16896       activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 1, 1, 512)    0           conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply_16 (Multiply)          (None, None, None, 5 0           stage4_unit3_conv2[0][0]         \n",
            "                                                                 activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, None, None, 5 0           multiply_16[0][0]                \n",
            "                                                                 add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "bn1 (BatchNormalization)        (None, None, None, 5 2048        add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "relu1 (Activation)              (None, None, None, 5 0           bn1[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage0_upsampling (UpSa (None, None, None, 5 0           relu1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage0_concat (Concaten (None, None, None, 7 0           decoder_stage0_upsampling[0][0]  \n",
            "                                                                 stage4_unit1_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage0a_conv (Conv2D)   (None, None, None, 2 1769472     decoder_stage0_concat[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage0a_bn (BatchNormal (None, None, None, 2 1024        decoder_stage0a_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage0a_relu (Activatio (None, None, None, 2 0           decoder_stage0a_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage0b_conv (Conv2D)   (None, None, None, 2 589824      decoder_stage0a_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage0b_bn (BatchNormal (None, None, None, 2 1024        decoder_stage0b_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage0b_relu (Activatio (None, None, None, 2 0           decoder_stage0b_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage1_upsampling (UpSa (None, None, None, 2 0           decoder_stage0b_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage1_concat (Concaten (None, None, None, 3 0           decoder_stage1_upsampling[0][0]  \n",
            "                                                                 stage3_unit1_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage1a_conv (Conv2D)   (None, None, None, 1 442368      decoder_stage1_concat[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage1a_bn (BatchNormal (None, None, None, 1 512         decoder_stage1a_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage1a_relu (Activatio (None, None, None, 1 0           decoder_stage1a_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage1b_conv (Conv2D)   (None, None, None, 1 147456      decoder_stage1a_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage1b_bn (BatchNormal (None, None, None, 1 512         decoder_stage1b_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage1b_relu (Activatio (None, None, None, 1 0           decoder_stage1b_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage2_upsampling (UpSa (None, None, None, 1 0           decoder_stage1b_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage2_concat (Concaten (None, None, None, 1 0           decoder_stage2_upsampling[0][0]  \n",
            "                                                                 stage2_unit1_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage2a_conv (Conv2D)   (None, None, None, 6 110592      decoder_stage2_concat[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage2a_bn (BatchNormal (None, None, None, 6 256         decoder_stage2a_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage2a_relu (Activatio (None, None, None, 6 0           decoder_stage2a_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage2b_conv (Conv2D)   (None, None, None, 6 36864       decoder_stage2a_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage2b_bn (BatchNormal (None, None, None, 6 256         decoder_stage2b_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage2b_relu (Activatio (None, None, None, 6 0           decoder_stage2b_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage3_upsampling (UpSa (None, None, None, 6 0           decoder_stage2b_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage3_concat (Concaten (None, None, None, 1 0           decoder_stage3_upsampling[0][0]  \n",
            "                                                                 relu0[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage3a_conv (Conv2D)   (None, None, None, 3 36864       decoder_stage3_concat[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage3a_bn (BatchNormal (None, None, None, 3 128         decoder_stage3a_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage3a_relu (Activatio (None, None, None, 3 0           decoder_stage3a_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage3b_conv (Conv2D)   (None, None, None, 3 9216        decoder_stage3a_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage3b_bn (BatchNormal (None, None, None, 3 128         decoder_stage3b_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage3b_relu (Activatio (None, None, None, 3 0           decoder_stage3b_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage4_upsampling (UpSa (None, None, None, 3 0           decoder_stage3b_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage4a_conv (Conv2D)   (None, None, None, 1 4608        decoder_stage4_upsampling[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage4a_bn (BatchNormal (None, None, None, 1 64          decoder_stage4a_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage4a_relu (Activatio (None, None, None, 1 0           decoder_stage4a_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage4b_conv (Conv2D)   (None, None, None, 1 2304        decoder_stage4a_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage4b_bn (BatchNormal (None, None, None, 1 64          decoder_stage4b_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage4b_relu (Activatio (None, None, None, 1 0           decoder_stage4b_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "final_conv (Conv2D)             (None, None, None, 1 145         decoder_stage4b_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "sigmoid (Activation)            (None, None, None, 1 0           final_conv[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 24,617,350\n",
            "Trainable params: 3,167,060\n",
            "Non-trainable params: 21,450,290\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZACnMm7VVHh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "3beb4e5f-58b3-49f1-9fcb-9996f93313a1"
      },
      "source": [
        "model.compile(\n",
        "    'Nadam',\n",
        "    loss=loss,\n",
        "    metrics=[dice_coefficient],\n",
        ")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5JfKnXBVVL0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "dc30ce07-553f-49f0-ea96-a8267eb22e31"
      },
      "source": [
        "lr_reduce = ReduceLROnPlateau(monitor='dice_coefficient', factor=0.1, epsilon=1e-5, patience=5, verbose=1)\n",
        "es = EarlyStopping(monitor='dice_coefficient', patience=100, verbose=1, mode='auto')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1335: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
            "  warnings.warn('`epsilon` argument is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMKYisXGVVPT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e92ee1dc-696b-4f57-aaa6-0dc485481457"
      },
      "source": [
        "model.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    batch_size=32,    \n",
        "    epochs=1000,\n",
        "    validation_data=(x_valid, y_valid),\n",
        "    callbacks=[lr_reduce, es]\n",
        ")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 384 samples, validate on 32 samples\n",
            "Epoch 1/1000\n",
            "384/384 [==============================] - 14s 38ms/step - loss: 15.7212 - dice_coefficient: 1.2941e-04 - val_loss: 33.4758 - val_dice_coefficient: 0.0000e+00\n",
            "Epoch 2/1000\n",
            "384/384 [==============================] - 4s 9ms/step - loss: 15.7554 - dice_coefficient: 6.9971e-06 - val_loss: 12.7368 - val_dice_coefficient: 0.0018\n",
            "Epoch 3/1000\n",
            "384/384 [==============================] - 4s 9ms/step - loss: 15.3625 - dice_coefficient: 3.4188e-04 - val_loss: 13.1358 - val_dice_coefficient: 0.0297\n",
            "Epoch 4/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.2295 - dice_coefficient: 0.0010 - val_loss: 18.6558 - val_dice_coefficient: 8.6524e-09\n",
            "Epoch 5/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.4409 - dice_coefficient: 5.4354e-05 - val_loss: 71.7108 - val_dice_coefficient: 0.0000e+00\n",
            "Epoch 6/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.3314 - dice_coefficient: 1.6273e-04 - val_loss: 343.8136 - val_dice_coefficient: 0.0000e+00\n",
            "Epoch 7/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.4042 - dice_coefficient: 7.0183e-05 - val_loss: 59.4488 - val_dice_coefficient: 0.0657\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "Epoch 8/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.4314 - dice_coefficient: 4.4156e-05 - val_loss: 39.7894 - val_dice_coefficient: 0.0000e+00\n",
            "Epoch 9/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.2805 - dice_coefficient: 2.6915e-04 - val_loss: 25.9821 - val_dice_coefficient: 0.0000e+00\n",
            "Epoch 10/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.2271 - dice_coefficient: 5.0999e-04 - val_loss: 30.5364 - val_dice_coefficient: 0.0000e+00\n",
            "Epoch 11/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1494 - dice_coefficient: 0.0013 - val_loss: 3.0862 - val_dice_coefficient: 0.1699\n",
            "Epoch 12/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1226 - dice_coefficient: 0.0018 - val_loss: 7.3220 - val_dice_coefficient: 0.2163\n",
            "\n",
            "Epoch 00012: ReduceLROnPlateau reducing learning rate to 2.0000000949949027e-05.\n",
            "Epoch 13/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1143 - dice_coefficient: 0.0019 - val_loss: 11.6363 - val_dice_coefficient: 0.2072\n",
            "Epoch 14/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1134 - dice_coefficient: 0.0020 - val_loss: 14.2585 - val_dice_coefficient: 0.2154\n",
            "Epoch 15/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1123 - dice_coefficient: 0.0020 - val_loss: 15.6676 - val_dice_coefficient: 0.2238\n",
            "Epoch 16/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1116 - dice_coefficient: 0.0020 - val_loss: 16.9474 - val_dice_coefficient: 0.2687\n",
            "Epoch 17/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1103 - dice_coefficient: 0.0020 - val_loss: 48.6920 - val_dice_coefficient: 0.3284\n",
            "\n",
            "Epoch 00017: ReduceLROnPlateau reducing learning rate to 2.0000001313746906e-06.\n",
            "Epoch 18/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1094 - dice_coefficient: 0.0020 - val_loss: 14.6259 - val_dice_coefficient: 0.3210\n",
            "Epoch 19/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1092 - dice_coefficient: 0.0020 - val_loss: 14.6290 - val_dice_coefficient: 0.3468\n",
            "Epoch 20/1000\n",
            "384/384 [==============================] - 4s 9ms/step - loss: 15.1091 - dice_coefficient: 0.0020 - val_loss: 20.6449 - val_dice_coefficient: 0.3267\n",
            "Epoch 21/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1090 - dice_coefficient: 0.0020 - val_loss: 22.1863 - val_dice_coefficient: 0.3328\n",
            "Epoch 22/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1088 - dice_coefficient: 0.0020 - val_loss: 26.9696 - val_dice_coefficient: 0.3364\n",
            "\n",
            "Epoch 00022: ReduceLROnPlateau reducing learning rate to 2.000000222324161e-07.\n",
            "Epoch 23/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1087 - dice_coefficient: 0.0021 - val_loss: 20.9545 - val_dice_coefficient: 0.3301\n",
            "Epoch 24/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1087 - dice_coefficient: 0.0021 - val_loss: 19.9604 - val_dice_coefficient: 0.3432\n",
            "Epoch 25/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1087 - dice_coefficient: 0.0021 - val_loss: 23.2006 - val_dice_coefficient: 0.3554\n",
            "Epoch 26/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1087 - dice_coefficient: 0.0021 - val_loss: 23.6604 - val_dice_coefficient: 0.3500\n",
            "Epoch 27/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1087 - dice_coefficient: 0.0021 - val_loss: 22.5540 - val_dice_coefficient: 0.3424\n",
            "\n",
            "Epoch 00027: ReduceLROnPlateau reducing learning rate to 2.000000165480742e-08.\n",
            "Epoch 28/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1087 - dice_coefficient: 0.0021 - val_loss: 23.3586 - val_dice_coefficient: 0.3401\n",
            "Epoch 29/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1087 - dice_coefficient: 0.0021 - val_loss: 24.6422 - val_dice_coefficient: 0.3448\n",
            "Epoch 30/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1087 - dice_coefficient: 0.0021 - val_loss: 23.5534 - val_dice_coefficient: 0.3453\n",
            "Epoch 31/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1087 - dice_coefficient: 0.0021 - val_loss: 24.3469 - val_dice_coefficient: 0.3417\n",
            "Epoch 32/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1087 - dice_coefficient: 0.0021 - val_loss: 25.4348 - val_dice_coefficient: 0.3386\n",
            "\n",
            "Epoch 00032: ReduceLROnPlateau reducing learning rate to 2.000000165480742e-09.\n",
            "Epoch 33/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1087 - dice_coefficient: 0.0021 - val_loss: 26.1098 - val_dice_coefficient: 0.3399\n",
            "Epoch 34/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1087 - dice_coefficient: 0.0021 - val_loss: 26.4989 - val_dice_coefficient: 0.3419\n",
            "Epoch 35/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1087 - dice_coefficient: 0.0021 - val_loss: 26.5696 - val_dice_coefficient: 0.3443\n",
            "Epoch 36/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1087 - dice_coefficient: 0.0021 - val_loss: 26.4755 - val_dice_coefficient: 0.3456\n",
            "Epoch 37/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1087 - dice_coefficient: 0.0021 - val_loss: 26.5794 - val_dice_coefficient: 0.3456\n",
            "\n",
            "Epoch 00037: ReduceLROnPlateau reducing learning rate to 2.000000165480742e-10.\n",
            "Epoch 38/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1087 - dice_coefficient: 0.0021 - val_loss: 26.2327 - val_dice_coefficient: 0.3459\n",
            "Epoch 39/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1087 - dice_coefficient: 0.0021 - val_loss: 24.9558 - val_dice_coefficient: 0.3459\n",
            "Epoch 40/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1087 - dice_coefficient: 0.0021 - val_loss: 25.2266 - val_dice_coefficient: 0.3461\n",
            "Epoch 41/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1087 - dice_coefficient: 0.0021 - val_loss: 25.2265 - val_dice_coefficient: 0.3462\n",
            "Epoch 42/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1087 - dice_coefficient: 0.0021 - val_loss: 25.1026 - val_dice_coefficient: 0.3466\n",
            "\n",
            "Epoch 00042: ReduceLROnPlateau reducing learning rate to 2.000000165480742e-11.\n",
            "Epoch 43/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1087 - dice_coefficient: 0.0021 - val_loss: 22.3832 - val_dice_coefficient: 0.3471\n",
            "Epoch 44/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1087 - dice_coefficient: 0.0021 - val_loss: 22.4641 - val_dice_coefficient: 0.3479\n",
            "Epoch 45/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1087 - dice_coefficient: 0.0021 - val_loss: 22.1606 - val_dice_coefficient: 0.3484\n",
            "Epoch 46/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1087 - dice_coefficient: 0.0021 - val_loss: 22.6299 - val_dice_coefficient: 0.3492\n",
            "Epoch 47/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1087 - dice_coefficient: 0.0021 - val_loss: 22.4206 - val_dice_coefficient: 0.3497\n",
            "\n",
            "Epoch 00047: ReduceLROnPlateau reducing learning rate to 2.000000165480742e-12.\n",
            "Epoch 48/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1087 - dice_coefficient: 0.0021 - val_loss: 22.8280 - val_dice_coefficient: 0.3501\n",
            "Epoch 49/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1087 - dice_coefficient: 0.0021 - val_loss: 22.4209 - val_dice_coefficient: 0.3503\n",
            "Epoch 50/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1087 - dice_coefficient: 0.0021 - val_loss: 22.5907 - val_dice_coefficient: 0.3505\n",
            "Epoch 51/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1087 - dice_coefficient: 0.0021 - val_loss: 22.9079 - val_dice_coefficient: 0.3507\n",
            "Epoch 52/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1087 - dice_coefficient: 0.0021 - val_loss: 23.0087 - val_dice_coefficient: 0.3508\n",
            "\n",
            "Epoch 00052: ReduceLROnPlateau reducing learning rate to 2.000000208848829e-13.\n",
            "Epoch 53/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1087 - dice_coefficient: 0.0021 - val_loss: 22.9440 - val_dice_coefficient: 0.3509\n",
            "Epoch 54/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1087 - dice_coefficient: 0.0021 - val_loss: 22.6146 - val_dice_coefficient: 0.3510\n",
            "Epoch 55/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1087 - dice_coefficient: 0.0021 - val_loss: 22.4695 - val_dice_coefficient: 0.3510\n",
            "Epoch 56/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1087 - dice_coefficient: 0.0021 - val_loss: 22.2783 - val_dice_coefficient: 0.3511\n",
            "Epoch 57/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1087 - dice_coefficient: 0.0021 - val_loss: 22.6844 - val_dice_coefficient: 0.3511\n",
            "\n",
            "Epoch 00057: ReduceLROnPlateau reducing learning rate to 2.0000002359538835e-14.\n",
            "Epoch 58/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1087 - dice_coefficient: 0.0021 - val_loss: 22.5208 - val_dice_coefficient: 0.3511\n",
            "Epoch 59/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1087 - dice_coefficient: 0.0021 - val_loss: 22.6155 - val_dice_coefficient: 0.3512\n",
            "Epoch 60/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1087 - dice_coefficient: 0.0021 - val_loss: 22.8080 - val_dice_coefficient: 0.3513\n",
            "Epoch 61/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1087 - dice_coefficient: 0.0021 - val_loss: 23.0239 - val_dice_coefficient: 0.3514\n",
            "Epoch 62/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1087 - dice_coefficient: 0.0021 - val_loss: 22.7680 - val_dice_coefficient: 0.3514\n",
            "\n",
            "Epoch 00062: ReduceLROnPlateau reducing learning rate to 2.000000303716519e-15.\n",
            "Epoch 63/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1087 - dice_coefficient: 0.0021 - val_loss: 23.0667 - val_dice_coefficient: 0.3515\n",
            "Epoch 64/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1087 - dice_coefficient: 0.0021 - val_loss: 23.3697 - val_dice_coefficient: 0.3514\n",
            "Epoch 65/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1087 - dice_coefficient: 0.0021 - val_loss: 23.3895 - val_dice_coefficient: 0.3513\n",
            "Epoch 66/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1087 - dice_coefficient: 0.0021 - val_loss: 23.3749 - val_dice_coefficient: 0.3514\n",
            "Epoch 67/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1087 - dice_coefficient: 0.0021 - val_loss: 25.9154 - val_dice_coefficient: 0.3513\n",
            "\n",
            "Epoch 00067: ReduceLROnPlateau reducing learning rate to 2.0000002190132243e-16.\n",
            "Epoch 68/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1087 - dice_coefficient: 0.0021 - val_loss: 25.9959 - val_dice_coefficient: 0.3513\n",
            "Epoch 69/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1087 - dice_coefficient: 0.0021 - val_loss: 26.2691 - val_dice_coefficient: 0.3513\n",
            "Epoch 70/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1087 - dice_coefficient: 0.0021 - val_loss: 26.4499 - val_dice_coefficient: 0.3513\n",
            "Epoch 71/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1087 - dice_coefficient: 0.0021 - val_loss: 26.3561 - val_dice_coefficient: 0.3513\n",
            "Epoch 72/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1087 - dice_coefficient: 0.0021 - val_loss: 25.8780 - val_dice_coefficient: 0.3513\n",
            "\n",
            "Epoch 00072: ReduceLROnPlateau reducing learning rate to 2.0000001660736652e-17.\n",
            "Epoch 73/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1087 - dice_coefficient: 0.0021 - val_loss: 26.3659 - val_dice_coefficient: 0.3513\n",
            "Epoch 74/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1087 - dice_coefficient: 0.0021 - val_loss: 26.6326 - val_dice_coefficient: 0.3514\n",
            "Epoch 75/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1087 - dice_coefficient: 0.0021 - val_loss: 26.6600 - val_dice_coefficient: 0.3514\n",
            "Epoch 76/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1087 - dice_coefficient: 0.0021 - val_loss: 26.6827 - val_dice_coefficient: 0.3514\n",
            "Epoch 77/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1087 - dice_coefficient: 0.0021 - val_loss: 26.4593 - val_dice_coefficient: 0.3514\n",
            "\n",
            "Epoch 00077: ReduceLROnPlateau reducing learning rate to 2.0000001329864408e-18.\n",
            "Epoch 78/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1087 - dice_coefficient: 0.0021 - val_loss: 23.4697 - val_dice_coefficient: 0.3514\n",
            "Epoch 79/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1087 - dice_coefficient: 0.0021 - val_loss: 23.0653 - val_dice_coefficient: 0.3517\n",
            "Epoch 80/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1087 - dice_coefficient: 0.0021 - val_loss: 23.3199 - val_dice_coefficient: 0.3516\n",
            "Epoch 81/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1087 - dice_coefficient: 0.0021 - val_loss: 23.4314 - val_dice_coefficient: 0.3515\n",
            "Epoch 82/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1087 - dice_coefficient: 0.0021 - val_loss: 22.8881 - val_dice_coefficient: 0.3517\n",
            "\n",
            "Epoch 00082: ReduceLROnPlateau reducing learning rate to 2.00000009162741e-19.\n",
            "Epoch 83/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1087 - dice_coefficient: 0.0021 - val_loss: 22.8403 - val_dice_coefficient: 0.3517\n",
            "Epoch 84/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1087 - dice_coefficient: 0.0021 - val_loss: 23.1261 - val_dice_coefficient: 0.3517\n",
            "Epoch 85/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1087 - dice_coefficient: 0.0021 - val_loss: 23.2119 - val_dice_coefficient: 0.3516\n",
            "Epoch 86/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1087 - dice_coefficient: 0.0021 - val_loss: 23.3579 - val_dice_coefficient: 0.3516\n",
            "Epoch 87/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1087 - dice_coefficient: 0.0021 - val_loss: 23.0774 - val_dice_coefficient: 0.3517\n",
            "\n",
            "Epoch 00087: ReduceLROnPlateau reducing learning rate to 2.000000065778016e-20.\n",
            "Epoch 88/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1087 - dice_coefficient: 0.0021 - val_loss: 22.8918 - val_dice_coefficient: 0.3517\n",
            "Epoch 89/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1087 - dice_coefficient: 0.0021 - val_loss: 23.1162 - val_dice_coefficient: 0.3517\n",
            "Epoch 90/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1087 - dice_coefficient: 0.0021 - val_loss: 23.1165 - val_dice_coefficient: 0.3517\n",
            "Epoch 91/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1087 - dice_coefficient: 0.0021 - val_loss: 23.2830 - val_dice_coefficient: 0.3516\n",
            "Epoch 92/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1087 - dice_coefficient: 0.0021 - val_loss: 23.4130 - val_dice_coefficient: 0.3516\n",
            "\n",
            "Epoch 00092: ReduceLROnPlateau reducing learning rate to 2.0000000980897586e-21.\n",
            "Epoch 93/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1087 - dice_coefficient: 0.0021 - val_loss: 22.8611 - val_dice_coefficient: 0.3517\n",
            "Epoch 94/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1087 - dice_coefficient: 0.0021 - val_loss: 22.9723 - val_dice_coefficient: 0.3517\n",
            "Epoch 95/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1087 - dice_coefficient: 0.0021 - val_loss: 22.8487 - val_dice_coefficient: 0.3517\n",
            "Epoch 96/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1087 - dice_coefficient: 0.0021 - val_loss: 22.8877 - val_dice_coefficient: 0.3517\n",
            "Epoch 97/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1087 - dice_coefficient: 0.0021 - val_loss: 22.8926 - val_dice_coefficient: 0.3517\n",
            "\n",
            "Epoch 00097: ReduceLROnPlateau reducing learning rate to 2.000000138479437e-22.\n",
            "Epoch 98/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1087 - dice_coefficient: 0.0021 - val_loss: 22.6801 - val_dice_coefficient: 0.3517\n",
            "Epoch 99/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1087 - dice_coefficient: 0.0021 - val_loss: 22.8387 - val_dice_coefficient: 0.3517\n",
            "Epoch 100/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1087 - dice_coefficient: 0.0021 - val_loss: 22.8172 - val_dice_coefficient: 0.3517\n",
            "Epoch 101/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1087 - dice_coefficient: 0.0021 - val_loss: 22.5629 - val_dice_coefficient: 0.3517\n",
            "Epoch 102/1000\n",
            "384/384 [==============================] - 4s 10ms/step - loss: 15.1087 - dice_coefficient: 0.0021 - val_loss: 22.8748 - val_dice_coefficient: 0.3517\n",
            "\n",
            "Epoch 00102: ReduceLROnPlateau reducing learning rate to 2.000000188966535e-23.\n",
            "Epoch 00102: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1d987b5898>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2jYwyNhVVSO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}