{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Semantic Segmentation V4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxXF5QkFKyoL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "42692d4c-3039-4129-c07f-2788310efaad"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chgjkCWIK8T5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0dd2cf1a-f37e-4e2f-b5cb-10cf94567207"
      },
      "source": [
        "cd 'drive/My Drive/'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y35bfbH2NvzV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "a8fe03c0-e624-4530-af76-a113419d321f"
      },
      "source": [
        "ls 'Capstone'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " convertVideotoCSV.py               test_video_list_and_name_mapping.zip\n",
            " EvaluationScriptsAndExamples.zip   test.zip\n",
            "'kaggle (1).json'                   \u001b[0m\u001b[01;34mtrain_color\u001b[0m/\n",
            " kaggle.json                        \u001b[01;34mtrain_label\u001b[0m/\n",
            " sample_submission.csv              train_label.zip\n",
            " sample_submission.csv.zip          train_video_list.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CcpoxYtrOaHP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "outputId": "e2630319-380f-400f-d6e3-b69d409622cb"
      },
      "source": [
        "!pip install segmentation_models"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: segmentation_models in /usr/local/lib/python3.6/dist-packages (1.0.0)\n",
            "Requirement already satisfied: keras-applications<=1.0.8,>=1.0.7 in /usr/local/lib/python3.6/dist-packages (from segmentation_models) (1.0.8)\n",
            "Requirement already satisfied: image-classifiers==1.0.0 in /usr/local/lib/python3.6/dist-packages (from segmentation_models) (1.0.0)\n",
            "Requirement already satisfied: efficientnet==1.0.0 in /usr/local/lib/python3.6/dist-packages (from segmentation_models) (1.0.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation_models) (2.8.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation_models) (1.17.4)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (from efficientnet==1.0.0->segmentation_models) (0.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->segmentation_models) (1.12.0)\n",
            "Requirement already satisfied: imageio>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2.4.1)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (4.3.0)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (1.1.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (1.3.3)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2.4)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (3.1.2)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.3.0->scikit-image->efficientnet==1.0.0->segmentation_models) (0.46)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image->efficientnet==1.0.0->segmentation_models) (4.4.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (2.6.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (1.1.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (2.4.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (42.0.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JePc5aHOROy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        },
        "outputId": "6c45a7c8-e073-421a-d3d3-649672edfc16"
      },
      "source": [
        "#Importing necessary libraries\n",
        "import os\n",
        "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"  #- Uncomment this to run tensorflow on CPU\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use(\"ggplot\")\n",
        "%matplotlib inline\n",
        "from glob import glob\n",
        "\n",
        "from tqdm import tqdm_notebook, tnrange\n",
        "from itertools import chain\n",
        "from skimage.io import imread, imshow, concatenate_images\n",
        "from skimage.transform import resize\n",
        "from skimage.morphology import label\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input, BatchNormalization, Activation, Dense, Dropout\n",
        "from keras.layers.core import Lambda, RepeatVector, Reshape\n",
        "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
        "from keras.layers.pooling import MaxPooling2D, GlobalMaxPool2D\n",
        "from keras.layers.merge import concatenate, add\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "\n",
        "import segmentation_models as sm"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Segmentation Models: using `keras` framework.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_cYcBoEOjaF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "acee9b8a-379c-4c42-81a8-aa0e3255cf0b"
      },
      "source": [
        "IMG_HEIGHT = 256\n",
        "IMG_WIDTH = 256\n",
        "\n",
        "IMG_DIR  = os.path.join('.', 'Capstone', 'train_color')\n",
        "MASK_DIR = os.path.join('.', 'Capstone', 'train_label')\n",
        "\n",
        "BACKBONE = 'resnet34'\n",
        "preprocess_input = sm.get_preprocessing(BACKBONE)\n",
        "\n",
        "INPUT_SIZE = (IMG_HEIGHT, IMG_WIDTH, 3)\n",
        "INPUT_MASK_SIZE = (IMG_HEIGHT, IMG_WIDTH, 1)\n",
        "\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "IMG_DIR, MASK_DIR"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./Capstone/train_color', './Capstone/train_label')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlA5LN6lPa0m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "9b5bdb20-f9fa-44a6-eafd-0a3ae11ec3c2"
      },
      "source": [
        "img_paths  = pd.DataFrame(dict(path = glob(os.path.join(IMG_DIR, '*.*j*g'))))\n",
        "mask_paths = pd.DataFrame(dict(path = glob(os.path.join(MASK_DIR, '*.*p*g'))))\n",
        "\n",
        "all_paths = img_paths.append(mask_paths)\n",
        "all_paths['group'] = all_paths['path'].map(lambda x: x.split(f'{os.sep}')[-2].split('_')[-1])\n",
        "all_paths['id'] = all_paths['path'].map(lambda x: '_'.join(os.path.splitext(os.path.basename(x))[0].split('_')[0:4]))\n",
        "all_paths.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>group</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>./Capstone/train_color/170908_061538269_Camera...</td>\n",
              "      <td>color</td>\n",
              "      <td>170908_061538269_Camera_5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>./Capstone/train_color/170908_061538269_Camera...</td>\n",
              "      <td>color</td>\n",
              "      <td>170908_061538269_Camera_6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>./Capstone/train_color/170908_061538547_Camera...</td>\n",
              "      <td>color</td>\n",
              "      <td>170908_061538547_Camera_6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>./Capstone/train_color/170908_061538825_Camera...</td>\n",
              "      <td>color</td>\n",
              "      <td>170908_061538825_Camera_5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>./Capstone/train_color/170908_061538825_Camera...</td>\n",
              "      <td>color</td>\n",
              "      <td>170908_061538825_Camera_6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                path  ...                         id\n",
              "0  ./Capstone/train_color/170908_061538269_Camera...  ...  170908_061538269_Camera_5\n",
              "1  ./Capstone/train_color/170908_061538269_Camera...  ...  170908_061538269_Camera_6\n",
              "2  ./Capstone/train_color/170908_061538547_Camera...  ...  170908_061538547_Camera_6\n",
              "3  ./Capstone/train_color/170908_061538825_Camera...  ...  170908_061538825_Camera_5\n",
              "4  ./Capstone/train_color/170908_061538825_Camera...  ...  170908_061538825_Camera_6\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FxdapODfhQD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a025a039-b43d-4c80-993b-6f8c9f9a1994"
      },
      "source": [
        "len(img_paths), len(mask_paths)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 2000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yhAFf_1PbTr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "8a6aa49c-d681-4157-f164-821941821968"
      },
      "source": [
        "group_df = all_paths.pivot_table(values = 'path', columns = 'group', aggfunc = 'first', index = ['id']).reset_index()\n",
        "group_df.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>group</th>\n",
              "      <th>id</th>\n",
              "      <th>color</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>170908_061502408_Camera_5</td>\n",
              "      <td>./Capstone/train_color/170908_061502408_Camera...</td>\n",
              "      <td>./Capstone/train_label/170908_061502408_Camera...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>170908_061502408_Camera_6</td>\n",
              "      <td>./Capstone/train_color/170908_061502408_Camera...</td>\n",
              "      <td>./Capstone/train_label/170908_061502408_Camera...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>170908_061502547_Camera_5</td>\n",
              "      <td>./Capstone/train_color/170908_061502547_Camera...</td>\n",
              "      <td>./Capstone/train_label/170908_061502547_Camera...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>170908_061502547_Camera_6</td>\n",
              "      <td>./Capstone/train_color/170908_061502547_Camera...</td>\n",
              "      <td>./Capstone/train_label/170908_061502547_Camera...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>170908_061502686_Camera_5</td>\n",
              "      <td>./Capstone/train_color/170908_061502686_Camera...</td>\n",
              "      <td>./Capstone/train_label/170908_061502686_Camera...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "group                         id  ...                                              label\n",
              "0      170908_061502408_Camera_5  ...  ./Capstone/train_label/170908_061502408_Camera...\n",
              "1      170908_061502408_Camera_6  ...  ./Capstone/train_label/170908_061502408_Camera...\n",
              "2      170908_061502547_Camera_5  ...  ./Capstone/train_label/170908_061502547_Camera...\n",
              "3      170908_061502547_Camera_6  ...  ./Capstone/train_label/170908_061502547_Camera...\n",
              "4      170908_061502686_Camera_5  ...  ./Capstone/train_label/170908_061502686_Camera...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EabmfrWAdD5a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "390d9363-5efd-4e56-b2a6-da6ef443c6c2"
      },
      "source": [
        "group_df.columns, group_df.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Index(['id', 'color', 'label'], dtype='object', name='group'), (2000, 3))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68iNOEViPbZY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_split_df, valid_split_df = train_test_split(group_df, random_state = 2018, test_size = 0.20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJoW9XK1-JCX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "958c78a4-deb9-4e4a-a68a-3aaf54e45eac"
      },
      "source": [
        "train_split_df.shape, valid_split_df.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1600, 3), (400, 3))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okyNLTdKQIcQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "\n",
        "def data_gen(df, size=16, normalize=True):\n",
        "    if size > df.shape[0]:\n",
        "        print('Size is bigger than available number of images. Please specify a smaller size than ', df.shape[0])\n",
        "        return\n",
        "    elif size < 0:\n",
        "        print('Size should be greater than zero ', df.shape[0])\n",
        "\n",
        "    ids = df['id'].tolist()\n",
        "    random.shuffle(ids)\n",
        "  \n",
        "    for i in range(size):\n",
        "        img = np.zeros((size, IMG_HEIGHT, IMG_WIDTH, 3)).astype('float')\n",
        "        mask = np.zeros((size, IMG_HEIGHT, IMG_WIDTH, 1)).astype('float')\n",
        "\n",
        "        img_path  = df.loc[df['id'] == ids[i]]['color'].values[0]\n",
        "        mask_path = df.loc[df['id'] == ids[i]]['label'].values[0]\n",
        "        #print(\"Pair:\")\n",
        "        #print(\"\\t\", img_path)\n",
        "        #print(\"\\t\", mask_path)\n",
        "\n",
        "        train_img = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)\n",
        "        #train_img = train_img[:,:,0]        # Just take one frame in order to reduce memory footprint of each image. This allows to load more images in memory.\n",
        "        if normalize:\n",
        "            train_img = train_img/255.\n",
        "        train_img =  cv2.resize(train_img, (IMG_WIDTH, IMG_HEIGHT)) # Resize\n",
        "        #train_img = train_img.reshape(IMG_HEIGHT, IMG_WIDTH, 1)\n",
        "\n",
        "        img[i] = train_img #add to array - img[0], img[1], and so on.\n",
        "\n",
        "\n",
        "        train_mask = cv2.imread(mask_path, cv2.IMREAD_UNCHANGED)\n",
        "        train_mask = np.where( np.logical_or(train_mask <33000, train_mask > 40000), 0, train_mask)\n",
        "        #train_mask = (t_mask//1000) + ((t_mask%1000)/100)            \n",
        "        train_mask = (train_mask//1000)    # Divide pixel value by 1000 and taking the integer will result in smaller value. e.g. 33001 will become 33 after this operation\n",
        "        train_mask = train_mask/40         # The highest number would be 40, so dividing it by 40 will ensure each pixel value is between 0 & 1 (both inclusive)\n",
        "\n",
        "        train_mask = cv2.resize(train_mask, (IMG_WIDTH, IMG_HEIGHT), interpolation = cv2.INTER_NEAREST)\n",
        "        train_mask = train_mask.reshape(IMG_HEIGHT, IMG_WIDTH, 1) # Add extra dimension for parity with train_img size [384 * 384 * 3]\n",
        "\n",
        "        mask[i] = train_mask\n",
        "\n",
        "        \n",
        "        if((i+1)%500 == 0):\n",
        "            random.shuffle(ids)\n",
        "            print('randomizing again')\n",
        "        \n",
        "    return img, mask"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDpARjKeQIgE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "6c34db75-c4d9-4c36-89b4-e9513235ae50"
      },
      "source": [
        "X_train, y_train = data_gen(train_split_df, size=1600, normalize=True)\n",
        "X_valid, y_valid = data_gen(valid_split_df, size=400, normalize=True)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "randomizing again\n",
            "randomizing again\n",
            "randomizing again\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4-Gtm1dQIju",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "034eef7f-ac1f-40e6-a65d-7dd769dea65f"
      },
      "source": [
        "X_train.shape, y_train.shape, X_valid.shape, y_valid.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1600, 256, 256, 3),\n",
              " (1600, 256, 256, 1),\n",
              " (400, 256, 256, 3),\n",
              " (400, 256, 256, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mt-nTAj_U0eA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dice_coefficient(y_true, y_pred):\n",
        "    numerator = 2 * tf.reduce_sum(y_true * y_pred)\n",
        "    denominator = tf.reduce_sum(y_true + y_pred)\n",
        "\n",
        "    return (numerator + 1)/ (denominator + 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98FUrrwwM8QJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dice_loss(y_true, y_pred):\n",
        "  return 1 - dice_coefficient(y_true, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkuWMmGaU0hT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "def loss(y_true, y_pred):\n",
        "    return categorical_crossentropy(y_true, y_pred) - tf.math.log(dice_coefficient(y_true, y_pred) + tf.keras.backend.epsilon())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-EdZMIaU0kQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2301fd04-664c-4053-cfbd-1b706e786330"
      },
      "source": [
        "x_train = preprocess_input(X_train)\n",
        "x_valid = preprocess_input(X_valid)\n",
        "#x_train = X_train\n",
        "#x_valid = X_valid\n",
        "\n",
        "model = sm.Unet(backbone_name=BACKBONE, encoder_weights='imagenet', input_shape=(None, None, 3), encoder_freeze=True)\n",
        "model.summary()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2239: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
            "\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "data (InputLayer)               (None, None, None, 3 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bn_data (BatchNormalization)    (None, None, None, 3 9           data[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_1 (ZeroPadding2D (None, None, None, 3 0           bn_data[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv0 (Conv2D)                  (None, None, None, 6 9408        zero_padding2d_1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "bn0 (BatchNormalization)        (None, None, None, 6 256         conv0[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "relu0 (Activation)              (None, None, None, 6 0           bn0[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_2 (ZeroPadding2D (None, None, None, 6 0           relu0[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "pooling0 (MaxPooling2D)         (None, None, None, 6 0           zero_padding2d_2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit1_bn1 (BatchNormaliz (None, None, None, 6 256         pooling0[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit1_relu1 (Activation) (None, None, None, 6 0           stage1_unit1_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_3 (ZeroPadding2D (None, None, None, 6 0           stage1_unit1_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit1_conv1 (Conv2D)     (None, None, None, 6 36864       zero_padding2d_3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit1_bn2 (BatchNormaliz (None, None, None, 6 256         stage1_unit1_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit1_relu2 (Activation) (None, None, None, 6 0           stage1_unit1_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_4 (ZeroPadding2D (None, None, None, 6 0           stage1_unit1_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit1_conv2 (Conv2D)     (None, None, None, 6 36864       zero_padding2d_4[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit1_sc (Conv2D)        (None, None, None, 6 4096        stage1_unit1_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, None, None, 6 0           stage1_unit1_conv2[0][0]         \n",
            "                                                                 stage1_unit1_sc[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit2_bn1 (BatchNormaliz (None, None, None, 6 256         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit2_relu1 (Activation) (None, None, None, 6 0           stage1_unit2_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_5 (ZeroPadding2D (None, None, None, 6 0           stage1_unit2_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit2_conv1 (Conv2D)     (None, None, None, 6 36864       zero_padding2d_5[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit2_bn2 (BatchNormaliz (None, None, None, 6 256         stage1_unit2_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit2_relu2 (Activation) (None, None, None, 6 0           stage1_unit2_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_6 (ZeroPadding2D (None, None, None, 6 0           stage1_unit2_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit2_conv2 (Conv2D)     (None, None, None, 6 36864       zero_padding2d_6[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, None, None, 6 0           stage1_unit2_conv2[0][0]         \n",
            "                                                                 add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit3_bn1 (BatchNormaliz (None, None, None, 6 256         add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit3_relu1 (Activation) (None, None, None, 6 0           stage1_unit3_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_7 (ZeroPadding2D (None, None, None, 6 0           stage1_unit3_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit3_conv1 (Conv2D)     (None, None, None, 6 36864       zero_padding2d_7[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit3_bn2 (BatchNormaliz (None, None, None, 6 256         stage1_unit3_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit3_relu2 (Activation) (None, None, None, 6 0           stage1_unit3_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_8 (ZeroPadding2D (None, None, None, 6 0           stage1_unit3_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit3_conv2 (Conv2D)     (None, None, None, 6 36864       zero_padding2d_8[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, None, None, 6 0           stage1_unit3_conv2[0][0]         \n",
            "                                                                 add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit1_bn1 (BatchNormaliz (None, None, None, 6 256         add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit1_relu1 (Activation) (None, None, None, 6 0           stage2_unit1_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_9 (ZeroPadding2D (None, None, None, 6 0           stage2_unit1_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit1_conv1 (Conv2D)     (None, None, None, 1 73728       zero_padding2d_9[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit1_bn2 (BatchNormaliz (None, None, None, 1 512         stage2_unit1_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit1_relu2 (Activation) (None, None, None, 1 0           stage2_unit1_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_10 (ZeroPadding2 (None, None, None, 1 0           stage2_unit1_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit1_conv2 (Conv2D)     (None, None, None, 1 147456      zero_padding2d_10[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit1_sc (Conv2D)        (None, None, None, 1 8192        stage2_unit1_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, None, None, 1 0           stage2_unit1_conv2[0][0]         \n",
            "                                                                 stage2_unit1_sc[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit2_bn1 (BatchNormaliz (None, None, None, 1 512         add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit2_relu1 (Activation) (None, None, None, 1 0           stage2_unit2_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_11 (ZeroPadding2 (None, None, None, 1 0           stage2_unit2_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit2_conv1 (Conv2D)     (None, None, None, 1 147456      zero_padding2d_11[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit2_bn2 (BatchNormaliz (None, None, None, 1 512         stage2_unit2_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit2_relu2 (Activation) (None, None, None, 1 0           stage2_unit2_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_12 (ZeroPadding2 (None, None, None, 1 0           stage2_unit2_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit2_conv2 (Conv2D)     (None, None, None, 1 147456      zero_padding2d_12[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, None, None, 1 0           stage2_unit2_conv2[0][0]         \n",
            "                                                                 add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit3_bn1 (BatchNormaliz (None, None, None, 1 512         add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit3_relu1 (Activation) (None, None, None, 1 0           stage2_unit3_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_13 (ZeroPadding2 (None, None, None, 1 0           stage2_unit3_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit3_conv1 (Conv2D)     (None, None, None, 1 147456      zero_padding2d_13[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit3_bn2 (BatchNormaliz (None, None, None, 1 512         stage2_unit3_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit3_relu2 (Activation) (None, None, None, 1 0           stage2_unit3_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_14 (ZeroPadding2 (None, None, None, 1 0           stage2_unit3_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit3_conv2 (Conv2D)     (None, None, None, 1 147456      zero_padding2d_14[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, None, None, 1 0           stage2_unit3_conv2[0][0]         \n",
            "                                                                 add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit4_bn1 (BatchNormaliz (None, None, None, 1 512         add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit4_relu1 (Activation) (None, None, None, 1 0           stage2_unit4_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_15 (ZeroPadding2 (None, None, None, 1 0           stage2_unit4_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit4_conv1 (Conv2D)     (None, None, None, 1 147456      zero_padding2d_15[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit4_bn2 (BatchNormaliz (None, None, None, 1 512         stage2_unit4_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit4_relu2 (Activation) (None, None, None, 1 0           stage2_unit4_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_16 (ZeroPadding2 (None, None, None, 1 0           stage2_unit4_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit4_conv2 (Conv2D)     (None, None, None, 1 147456      zero_padding2d_16[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, None, None, 1 0           stage2_unit4_conv2[0][0]         \n",
            "                                                                 add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit1_bn1 (BatchNormaliz (None, None, None, 1 512         add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit1_relu1 (Activation) (None, None, None, 1 0           stage3_unit1_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_17 (ZeroPadding2 (None, None, None, 1 0           stage3_unit1_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit1_conv1 (Conv2D)     (None, None, None, 2 294912      zero_padding2d_17[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit1_bn2 (BatchNormaliz (None, None, None, 2 1024        stage3_unit1_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit1_relu2 (Activation) (None, None, None, 2 0           stage3_unit1_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_18 (ZeroPadding2 (None, None, None, 2 0           stage3_unit1_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit1_conv2 (Conv2D)     (None, None, None, 2 589824      zero_padding2d_18[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit1_sc (Conv2D)        (None, None, None, 2 32768       stage3_unit1_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, None, None, 2 0           stage3_unit1_conv2[0][0]         \n",
            "                                                                 stage3_unit1_sc[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit2_bn1 (BatchNormaliz (None, None, None, 2 1024        add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit2_relu1 (Activation) (None, None, None, 2 0           stage3_unit2_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_19 (ZeroPadding2 (None, None, None, 2 0           stage3_unit2_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit2_conv1 (Conv2D)     (None, None, None, 2 589824      zero_padding2d_19[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit2_bn2 (BatchNormaliz (None, None, None, 2 1024        stage3_unit2_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit2_relu2 (Activation) (None, None, None, 2 0           stage3_unit2_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_20 (ZeroPadding2 (None, None, None, 2 0           stage3_unit2_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit2_conv2 (Conv2D)     (None, None, None, 2 589824      zero_padding2d_20[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, None, None, 2 0           stage3_unit2_conv2[0][0]         \n",
            "                                                                 add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit3_bn1 (BatchNormaliz (None, None, None, 2 1024        add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit3_relu1 (Activation) (None, None, None, 2 0           stage3_unit3_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_21 (ZeroPadding2 (None, None, None, 2 0           stage3_unit3_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit3_conv1 (Conv2D)     (None, None, None, 2 589824      zero_padding2d_21[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit3_bn2 (BatchNormaliz (None, None, None, 2 1024        stage3_unit3_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit3_relu2 (Activation) (None, None, None, 2 0           stage3_unit3_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_22 (ZeroPadding2 (None, None, None, 2 0           stage3_unit3_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit3_conv2 (Conv2D)     (None, None, None, 2 589824      zero_padding2d_22[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, None, None, 2 0           stage3_unit3_conv2[0][0]         \n",
            "                                                                 add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit4_bn1 (BatchNormaliz (None, None, None, 2 1024        add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit4_relu1 (Activation) (None, None, None, 2 0           stage3_unit4_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_23 (ZeroPadding2 (None, None, None, 2 0           stage3_unit4_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit4_conv1 (Conv2D)     (None, None, None, 2 589824      zero_padding2d_23[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit4_bn2 (BatchNormaliz (None, None, None, 2 1024        stage3_unit4_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit4_relu2 (Activation) (None, None, None, 2 0           stage3_unit4_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_24 (ZeroPadding2 (None, None, None, 2 0           stage3_unit4_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit4_conv2 (Conv2D)     (None, None, None, 2 589824      zero_padding2d_24[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, None, None, 2 0           stage3_unit4_conv2[0][0]         \n",
            "                                                                 add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit5_bn1 (BatchNormaliz (None, None, None, 2 1024        add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit5_relu1 (Activation) (None, None, None, 2 0           stage3_unit5_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_25 (ZeroPadding2 (None, None, None, 2 0           stage3_unit5_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit5_conv1 (Conv2D)     (None, None, None, 2 589824      zero_padding2d_25[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit5_bn2 (BatchNormaliz (None, None, None, 2 1024        stage3_unit5_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit5_relu2 (Activation) (None, None, None, 2 0           stage3_unit5_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_26 (ZeroPadding2 (None, None, None, 2 0           stage3_unit5_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit5_conv2 (Conv2D)     (None, None, None, 2 589824      zero_padding2d_26[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, None, None, 2 0           stage3_unit5_conv2[0][0]         \n",
            "                                                                 add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit6_bn1 (BatchNormaliz (None, None, None, 2 1024        add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit6_relu1 (Activation) (None, None, None, 2 0           stage3_unit6_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_27 (ZeroPadding2 (None, None, None, 2 0           stage3_unit6_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit6_conv1 (Conv2D)     (None, None, None, 2 589824      zero_padding2d_27[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit6_bn2 (BatchNormaliz (None, None, None, 2 1024        stage3_unit6_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit6_relu2 (Activation) (None, None, None, 2 0           stage3_unit6_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_28 (ZeroPadding2 (None, None, None, 2 0           stage3_unit6_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit6_conv2 (Conv2D)     (None, None, None, 2 589824      zero_padding2d_28[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, None, None, 2 0           stage3_unit6_conv2[0][0]         \n",
            "                                                                 add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit1_bn1 (BatchNormaliz (None, None, None, 2 1024        add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit1_relu1 (Activation) (None, None, None, 2 0           stage4_unit1_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_29 (ZeroPadding2 (None, None, None, 2 0           stage4_unit1_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit1_conv1 (Conv2D)     (None, None, None, 5 1179648     zero_padding2d_29[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit1_bn2 (BatchNormaliz (None, None, None, 5 2048        stage4_unit1_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit1_relu2 (Activation) (None, None, None, 5 0           stage4_unit1_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_30 (ZeroPadding2 (None, None, None, 5 0           stage4_unit1_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit1_conv2 (Conv2D)     (None, None, None, 5 2359296     zero_padding2d_30[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit1_sc (Conv2D)        (None, None, None, 5 131072      stage4_unit1_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, None, None, 5 0           stage4_unit1_conv2[0][0]         \n",
            "                                                                 stage4_unit1_sc[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit2_bn1 (BatchNormaliz (None, None, None, 5 2048        add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit2_relu1 (Activation) (None, None, None, 5 0           stage4_unit2_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_31 (ZeroPadding2 (None, None, None, 5 0           stage4_unit2_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit2_conv1 (Conv2D)     (None, None, None, 5 2359296     zero_padding2d_31[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit2_bn2 (BatchNormaliz (None, None, None, 5 2048        stage4_unit2_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit2_relu2 (Activation) (None, None, None, 5 0           stage4_unit2_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_32 (ZeroPadding2 (None, None, None, 5 0           stage4_unit2_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit2_conv2 (Conv2D)     (None, None, None, 5 2359296     zero_padding2d_32[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, None, None, 5 0           stage4_unit2_conv2[0][0]         \n",
            "                                                                 add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit3_bn1 (BatchNormaliz (None, None, None, 5 2048        add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit3_relu1 (Activation) (None, None, None, 5 0           stage4_unit3_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_33 (ZeroPadding2 (None, None, None, 5 0           stage4_unit3_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit3_conv1 (Conv2D)     (None, None, None, 5 2359296     zero_padding2d_33[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit3_bn2 (BatchNormaliz (None, None, None, 5 2048        stage4_unit3_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit3_relu2 (Activation) (None, None, None, 5 0           stage4_unit3_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_34 (ZeroPadding2 (None, None, None, 5 0           stage4_unit3_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit3_conv2 (Conv2D)     (None, None, None, 5 2359296     zero_padding2d_34[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, None, None, 5 0           stage4_unit3_conv2[0][0]         \n",
            "                                                                 add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "bn1 (BatchNormalization)        (None, None, None, 5 2048        add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "relu1 (Activation)              (None, None, None, 5 0           bn1[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage0_upsampling (UpSa (None, None, None, 5 0           relu1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage0_concat (Concaten (None, None, None, 7 0           decoder_stage0_upsampling[0][0]  \n",
            "                                                                 stage4_unit1_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage0a_conv (Conv2D)   (None, None, None, 2 1769472     decoder_stage0_concat[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage0a_bn (BatchNormal (None, None, None, 2 1024        decoder_stage0a_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage0a_relu (Activatio (None, None, None, 2 0           decoder_stage0a_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage0b_conv (Conv2D)   (None, None, None, 2 589824      decoder_stage0a_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage0b_bn (BatchNormal (None, None, None, 2 1024        decoder_stage0b_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage0b_relu (Activatio (None, None, None, 2 0           decoder_stage0b_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage1_upsampling (UpSa (None, None, None, 2 0           decoder_stage0b_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage1_concat (Concaten (None, None, None, 3 0           decoder_stage1_upsampling[0][0]  \n",
            "                                                                 stage3_unit1_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage1a_conv (Conv2D)   (None, None, None, 1 442368      decoder_stage1_concat[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage1a_bn (BatchNormal (None, None, None, 1 512         decoder_stage1a_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage1a_relu (Activatio (None, None, None, 1 0           decoder_stage1a_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage1b_conv (Conv2D)   (None, None, None, 1 147456      decoder_stage1a_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage1b_bn (BatchNormal (None, None, None, 1 512         decoder_stage1b_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage1b_relu (Activatio (None, None, None, 1 0           decoder_stage1b_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage2_upsampling (UpSa (None, None, None, 1 0           decoder_stage1b_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage2_concat (Concaten (None, None, None, 1 0           decoder_stage2_upsampling[0][0]  \n",
            "                                                                 stage2_unit1_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage2a_conv (Conv2D)   (None, None, None, 6 110592      decoder_stage2_concat[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage2a_bn (BatchNormal (None, None, None, 6 256         decoder_stage2a_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage2a_relu (Activatio (None, None, None, 6 0           decoder_stage2a_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage2b_conv (Conv2D)   (None, None, None, 6 36864       decoder_stage2a_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage2b_bn (BatchNormal (None, None, None, 6 256         decoder_stage2b_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage2b_relu (Activatio (None, None, None, 6 0           decoder_stage2b_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage3_upsampling (UpSa (None, None, None, 6 0           decoder_stage2b_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage3_concat (Concaten (None, None, None, 1 0           decoder_stage3_upsampling[0][0]  \n",
            "                                                                 relu0[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage3a_conv (Conv2D)   (None, None, None, 3 36864       decoder_stage3_concat[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage3a_bn (BatchNormal (None, None, None, 3 128         decoder_stage3a_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage3a_relu (Activatio (None, None, None, 3 0           decoder_stage3a_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage3b_conv (Conv2D)   (None, None, None, 3 9216        decoder_stage3a_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage3b_bn (BatchNormal (None, None, None, 3 128         decoder_stage3b_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage3b_relu (Activatio (None, None, None, 3 0           decoder_stage3b_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage4_upsampling (UpSa (None, None, None, 3 0           decoder_stage3b_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage4a_conv (Conv2D)   (None, None, None, 1 4608        decoder_stage4_upsampling[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage4a_bn (BatchNormal (None, None, None, 1 64          decoder_stage4a_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage4a_relu (Activatio (None, None, None, 1 0           decoder_stage4a_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage4b_conv (Conv2D)   (None, None, None, 1 2304        decoder_stage4a_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage4b_bn (BatchNormal (None, None, None, 1 64          decoder_stage4b_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage4b_relu (Activatio (None, None, None, 1 0           decoder_stage4b_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "final_conv (Conv2D)             (None, None, None, 1 145         decoder_stage4b_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "sigmoid (Activation)            (None, None, None, 1 0           final_conv[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 24,456,154\n",
            "Trainable params: 3,167,060\n",
            "Non-trainable params: 21,289,094\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZACnMm7VVHh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "f069a3ff-c86a-4b13-8e02-87df8c6524b2"
      },
      "source": [
        "model.compile(\n",
        "    'RMSprop',\n",
        "    loss=dice_loss,\n",
        "    metrics=[dice_coefficient],\n",
        ")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5JfKnXBVVL0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "a5bffd1f-2ee8-4b27-e65c-cc5b821113b0"
      },
      "source": [
        "lr_reduce = ReduceLROnPlateau(monitor='dice_coefficient', factor=0.1, epsilon=1e-5, patience=5, verbose=1)\n",
        "es = EarlyStopping(monitor='dice_coefficient', patience=50, verbose=1, mode='auto')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1335: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
            "  warnings.warn('`epsilon` argument is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMKYisXGVVPT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a9a69121-5c23-400f-9382-0213d36eecbb"
      },
      "source": [
        "model.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    batch_size=32,    \n",
        "    epochs=1000,\n",
        "    validation_data=(x_valid, y_valid),\n",
        "    callbacks=[lr_reduce, es]\n",
        ")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/1000\n",
            "1600/1600 [==============================] - 51s 32ms/step - loss: 1.0000 - dice_coefficient: 3.6635e-06 - val_loss: 0.9999 - val_dice_coefficient: 1.0604e-04\n",
            "Epoch 2/1000\n",
            "1600/1600 [==============================] - 33s 21ms/step - loss: 0.9999 - dice_coefficient: 8.5863e-05 - val_loss: 0.9991 - val_dice_coefficient: 9.1126e-04\n",
            "Epoch 3/1000\n",
            "1600/1600 [==============================] - 33s 21ms/step - loss: 0.8300 - dice_coefficient: 0.1700 - val_loss: 0.9818 - val_dice_coefficient: 0.0182\n",
            "Epoch 4/1000\n",
            "1600/1600 [==============================] - 34s 21ms/step - loss: 0.0837 - dice_coefficient: 0.9163 - val_loss: 0.5155 - val_dice_coefficient: 0.4845\n",
            "Epoch 5/1000\n",
            "1600/1600 [==============================] - 34s 21ms/step - loss: 0.0219 - dice_coefficient: 0.9781 - val_loss: 0.1766 - val_dice_coefficient: 0.8234\n",
            "Epoch 6/1000\n",
            "1600/1600 [==============================] - 34s 21ms/step - loss: 0.0193 - dice_coefficient: 0.9807 - val_loss: 0.1071 - val_dice_coefficient: 0.8929\n",
            "\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "Epoch 7/1000\n",
            "1600/1600 [==============================] - 33s 21ms/step - loss: 0.0193 - dice_coefficient: 0.9807 - val_loss: 0.0627 - val_dice_coefficient: 0.9373\n",
            "Epoch 8/1000\n",
            "1600/1600 [==============================] - 33s 21ms/step - loss: 0.0193 - dice_coefficient: 0.9807 - val_loss: 0.0487 - val_dice_coefficient: 0.9513\n",
            "Epoch 9/1000\n",
            "1600/1600 [==============================] - 33s 21ms/step - loss: 0.0193 - dice_coefficient: 0.9807 - val_loss: 0.0381 - val_dice_coefficient: 0.9619\n",
            "Epoch 10/1000\n",
            "1600/1600 [==============================] - 33s 21ms/step - loss: 0.0193 - dice_coefficient: 0.9807 - val_loss: 0.0380 - val_dice_coefficient: 0.9620\n",
            "Epoch 11/1000\n",
            "1600/1600 [==============================] - 33s 21ms/step - loss: 0.0193 - dice_coefficient: 0.9807 - val_loss: 0.0380 - val_dice_coefficient: 0.9620\n",
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "Epoch 12/1000\n",
            "1600/1600 [==============================] - 33s 21ms/step - loss: 0.0193 - dice_coefficient: 0.9807 - val_loss: 0.0378 - val_dice_coefficient: 0.9622\n",
            "Epoch 13/1000\n",
            "1600/1600 [==============================] - 33s 21ms/step - loss: 0.0193 - dice_coefficient: 0.9807 - val_loss: 0.0378 - val_dice_coefficient: 0.9622\n",
            "Epoch 14/1000\n",
            "1600/1600 [==============================] - 33s 21ms/step - loss: 0.0193 - dice_coefficient: 0.9807 - val_loss: 0.0378 - val_dice_coefficient: 0.9622\n",
            "Epoch 15/1000\n",
            "1600/1600 [==============================] - 33s 21ms/step - loss: 0.0193 - dice_coefficient: 0.9807 - val_loss: 0.0377 - val_dice_coefficient: 0.9623\n",
            "Epoch 16/1000\n",
            "1600/1600 [==============================] - 33s 21ms/step - loss: 0.0193 - dice_coefficient: 0.9807 - val_loss: 0.0377 - val_dice_coefficient: 0.9623\n",
            "\n",
            "Epoch 00016: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
            "Epoch 17/1000\n",
            "1600/1600 [==============================] - 33s 21ms/step - loss: 0.0193 - dice_coefficient: 0.9807 - val_loss: 0.0377 - val_dice_coefficient: 0.9623\n",
            "Epoch 18/1000\n",
            "1600/1600 [==============================] - 33s 21ms/step - loss: 0.0193 - dice_coefficient: 0.9807 - val_loss: 0.0378 - val_dice_coefficient: 0.9622\n",
            "Epoch 19/1000\n",
            "1600/1600 [==============================] - 33s 21ms/step - loss: 0.0193 - dice_coefficient: 0.9807 - val_loss: 0.0377 - val_dice_coefficient: 0.9623\n",
            "Epoch 20/1000\n",
            "1600/1600 [==============================] - 33s 21ms/step - loss: 0.0193 - dice_coefficient: 0.9807 - val_loss: 0.0377 - val_dice_coefficient: 0.9623\n",
            "Epoch 21/1000\n",
            "1600/1600 [==============================] - 33s 21ms/step - loss: 0.0193 - dice_coefficient: 0.9807 - val_loss: 0.0378 - val_dice_coefficient: 0.9622\n",
            "\n",
            "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
            "Epoch 22/1000\n",
            "1600/1600 [==============================] - 33s 21ms/step - loss: 0.0193 - dice_coefficient: 0.9807 - val_loss: 0.0379 - val_dice_coefficient: 0.9621\n",
            "Epoch 23/1000\n",
            "1600/1600 [==============================] - 33s 21ms/step - loss: 0.0193 - dice_coefficient: 0.9807 - val_loss: 0.0378 - val_dice_coefficient: 0.9622\n",
            "Epoch 24/1000\n",
            "1600/1600 [==============================] - 33s 21ms/step - loss: 0.0193 - dice_coefficient: 0.9807 - val_loss: 0.0379 - val_dice_coefficient: 0.9621\n",
            "Epoch 25/1000\n",
            "1600/1600 [==============================] - 33s 21ms/step - loss: 0.0193 - dice_coefficient: 0.9807 - val_loss: 0.0378 - val_dice_coefficient: 0.9622\n",
            "Epoch 26/1000\n",
            "1600/1600 [==============================] - 33s 21ms/step - loss: 0.0193 - dice_coefficient: 0.9807 - val_loss: 0.0377 - val_dice_coefficient: 0.9623\n",
            "\n",
            "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
            "Epoch 27/1000\n",
            "1600/1600 [==============================] - 33s 21ms/step - loss: 0.0193 - dice_coefficient: 0.9807 - val_loss: 0.0377 - val_dice_coefficient: 0.9623\n",
            "Epoch 28/1000\n",
            "1600/1600 [==============================] - 33s 21ms/step - loss: 0.0193 - dice_coefficient: 0.9807 - val_loss: 0.0377 - val_dice_coefficient: 0.9623\n",
            "Epoch 29/1000\n",
            "1600/1600 [==============================] - 33s 21ms/step - loss: 0.0193 - dice_coefficient: 0.9807 - val_loss: 0.0377 - val_dice_coefficient: 0.9623\n",
            "Epoch 30/1000\n",
            "1600/1600 [==============================] - 33s 21ms/step - loss: 0.0193 - dice_coefficient: 0.9807 - val_loss: 0.0377 - val_dice_coefficient: 0.9623\n",
            "Epoch 31/1000\n",
            "1600/1600 [==============================] - 33s 21ms/step - loss: 0.0193 - dice_coefficient: 0.9807 - val_loss: 0.0377 - val_dice_coefficient: 0.9623\n",
            "\n",
            "Epoch 00031: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
            "Epoch 32/1000\n",
            "1600/1600 [==============================] - 33s 21ms/step - loss: 0.0193 - dice_coefficient: 0.9807 - val_loss: 0.0377 - val_dice_coefficient: 0.9623\n",
            "Epoch 33/1000\n",
            "1600/1600 [==============================] - 33s 21ms/step - loss: 0.0193 - dice_coefficient: 0.9807 - val_loss: 0.0377 - val_dice_coefficient: 0.9623\n",
            "Epoch 34/1000\n",
            "1600/1600 [==============================] - 33s 21ms/step - loss: 0.0193 - dice_coefficient: 0.9807 - val_loss: 0.0377 - val_dice_coefficient: 0.9623\n",
            "Epoch 35/1000\n",
            "1600/1600 [==============================] - 33s 21ms/step - loss: 0.0193 - dice_coefficient: 0.9807 - val_loss: 0.0377 - val_dice_coefficient: 0.9623\n",
            "Epoch 36/1000\n",
            "1600/1600 [==============================] - 33s 21ms/step - loss: 0.0193 - dice_coefficient: 0.9807 - val_loss: 0.0377 - val_dice_coefficient: 0.9623\n",
            "\n",
            "Epoch 00036: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
            "Epoch 37/1000\n",
            "1600/1600 [==============================] - 33s 21ms/step - loss: 0.0193 - dice_coefficient: 0.9807 - val_loss: 0.0377 - val_dice_coefficient: 0.9623\n",
            "Epoch 38/1000\n",
            "1600/1600 [==============================] - 33s 21ms/step - loss: 0.0193 - dice_coefficient: 0.9807 - val_loss: 0.0378 - val_dice_coefficient: 0.9622\n",
            "Epoch 39/1000\n",
            "1600/1600 [==============================] - 33s 21ms/step - loss: 0.0193 - dice_coefficient: 0.9807 - val_loss: 0.0379 - val_dice_coefficient: 0.9621\n",
            "Epoch 40/1000\n",
            "1600/1600 [==============================] - 33s 21ms/step - loss: 0.0193 - dice_coefficient: 0.9807 - val_loss: 0.0378 - val_dice_coefficient: 0.9622\n",
            "Epoch 41/1000\n",
            "1600/1600 [==============================] - 33s 21ms/step - loss: 0.0193 - dice_coefficient: 0.9807 - val_loss: 0.0377 - val_dice_coefficient: 0.9623\n",
            "\n",
            "Epoch 00041: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.\n",
            "Epoch 42/1000\n",
            "1600/1600 [==============================] - 33s 21ms/step - loss: 0.0193 - dice_coefficient: 0.9807 - val_loss: 0.0377 - val_dice_coefficient: 0.9623\n",
            "Epoch 43/1000\n",
            "1600/1600 [==============================] - 33s 21ms/step - loss: 0.0193 - dice_coefficient: 0.9807 - val_loss: 0.0377 - val_dice_coefficient: 0.9623\n",
            "Epoch 44/1000\n",
            "1600/1600 [==============================] - 33s 21ms/step - loss: 0.0193 - dice_coefficient: 0.9807 - val_loss: 0.0378 - val_dice_coefficient: 0.9622\n",
            "Epoch 45/1000\n",
            "1600/1600 [==============================] - 33s 21ms/step - loss: 0.0193 - dice_coefficient: 0.9807 - val_loss: 0.0379 - val_dice_coefficient: 0.9621\n",
            "Epoch 46/1000\n",
            "1600/1600 [==============================] - 33s 21ms/step - loss: 0.0193 - dice_coefficient: 0.9807 - val_loss: 0.0377 - val_dice_coefficient: 0.9623\n",
            "\n",
            "Epoch 00046: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-12.\n",
            "Epoch 47/1000\n",
            "1600/1600 [==============================] - 33s 21ms/step - loss: 0.0193 - dice_coefficient: 0.9807 - val_loss: 0.0378 - val_dice_coefficient: 0.9622\n",
            "Epoch 48/1000\n",
            "1600/1600 [==============================] - 33s 21ms/step - loss: 0.0193 - dice_coefficient: 0.9807 - val_loss: 0.0378 - val_dice_coefficient: 0.9622\n",
            "Epoch 49/1000\n",
            "1600/1600 [==============================] - 33s 21ms/step - loss: 0.0193 - dice_coefficient: 0.9807 - val_loss: 0.0378 - val_dice_coefficient: 0.9622\n",
            "Epoch 50/1000\n",
            "1600/1600 [==============================] - 33s 21ms/step - loss: 0.0193 - dice_coefficient: 0.9807 - val_loss: 0.0377 - val_dice_coefficient: 0.9623\n",
            "Epoch 51/1000\n",
            "1600/1600 [==============================] - 33s 21ms/step - loss: 0.0193 - dice_coefficient: 0.9807 - val_loss: 0.0378 - val_dice_coefficient: 0.9622\n",
            "\n",
            "Epoch 00051: ReduceLROnPlateau reducing learning rate to 1.0000001044244145e-13.\n",
            "Epoch 00051: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5c05fd5f60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2jYwyNhVVSO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1f700a4c-9407-4dfd-8117-0691412aeb1a"
      },
      "source": [
        "preds_val = model.predict(x_valid, verbose=1)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "400/400 [==============================] - 4s 9ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oglBq0cfo9b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0f63974a-91b4-4a7a-8ca4-f3875621828a"
      },
      "source": [
        "preds_val.shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(400, 256, 256, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddq2vDxdgZyn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c83d0d08-194d-48b3-d776-e4800a06b09e"
      },
      "source": [
        "pred_mask = preds_val[10].reshape(IMG_HEIGHT, IMG_WIDTH)\n",
        "pred_mask = pred_mask * 40 * 1000\n",
        "pred_mask.shape"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(256, 256)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBLKP-5Ygvdm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "f5846669-824e-4ce0-8ffd-cac2671576de"
      },
      "source": [
        "pd.DataFrame(pred_mask)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>216</th>\n",
              "      <th>217</th>\n",
              "      <th>218</th>\n",
              "      <th>219</th>\n",
              "      <th>220</th>\n",
              "      <th>221</th>\n",
              "      <th>222</th>\n",
              "      <th>223</th>\n",
              "      <th>224</th>\n",
              "      <th>225</th>\n",
              "      <th>226</th>\n",
              "      <th>227</th>\n",
              "      <th>228</th>\n",
              "      <th>229</th>\n",
              "      <th>230</th>\n",
              "      <th>231</th>\n",
              "      <th>232</th>\n",
              "      <th>233</th>\n",
              "      <th>234</th>\n",
              "      <th>235</th>\n",
              "      <th>236</th>\n",
              "      <th>237</th>\n",
              "      <th>238</th>\n",
              "      <th>239</th>\n",
              "      <th>240</th>\n",
              "      <th>241</th>\n",
              "      <th>242</th>\n",
              "      <th>243</th>\n",
              "      <th>244</th>\n",
              "      <th>245</th>\n",
              "      <th>246</th>\n",
              "      <th>247</th>\n",
              "      <th>248</th>\n",
              "      <th>249</th>\n",
              "      <th>250</th>\n",
              "      <th>251</th>\n",
              "      <th>252</th>\n",
              "      <th>253</th>\n",
              "      <th>254</th>\n",
              "      <th>255</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.002384</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.002384</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>251</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>252</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>253</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>254</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>255</th>\n",
              "      <td>0.005960</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.003576</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>256 rows × 256 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          0    1    2    3    4    5    ...  250  251  252  253  254       255\n",
              "0    0.002384  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.002384\n",
              "1    0.000000  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.000000\n",
              "2    0.000000  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.000000\n",
              "3    0.000000  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.000000\n",
              "4    0.000000  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.000000\n",
              "..        ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...       ...\n",
              "251  0.000000  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.000000\n",
              "252  0.000000  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.000000\n",
              "253  0.000000  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.000000\n",
              "254  0.000000  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.000000\n",
              "255  0.005960  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.003576\n",
              "\n",
              "[256 rows x 256 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U27-2DUlhf8p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "outputId": "fd0cf21d-1587-40e2-ab3c-f6ab42b209e4"
      },
      "source": [
        "imshow(pred_mask)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/skimage/io/_plugins/matplotlib_plugin.py:75: UserWarning: Low image data range; displaying image with stretched contrast.\n",
            "  warn(\"Low image data range; displaying image with \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f5c05c28198>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVEAAAEYCAYAAADlIcXmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}